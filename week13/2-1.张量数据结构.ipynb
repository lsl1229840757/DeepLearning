{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600240629119",
   "display_name": "Python 3.7.0 64-bit ('pytorch1.6': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2-1 张量数据结构\n",
    "Pytorch的基本数据结构是张量Tensor。张量即多维数组。Pytorch的张量和numpy中的array很类似。\n",
    "\n",
    "本节我们主要介绍张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等基本概念。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 一、张量的数据类型\n",
    "张量的数据类型和numpy.array基本一一, 但是不支持**str**类型。\n",
    "包括:\n",
    "* torch.float64(torch.double)\n",
    "* **torch.float32(torch.float)**\n",
    "* torch.float16\n",
    "* torch.int64(torch.long)\n",
    "* torch.int32(torch.int)\n",
    "* torch.int16\n",
    "* torch.int8\n",
    "* torch.unit8\n",
    "* torch.bool\n",
    "一般神经网络模型使用的都是torch.float32类型\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(1) torch.int64\ntensor(2.) torch.float32\ntensor(True) torch.bool\n"
    }
   ],
   "source": [
    "# 自动推断数据类型\n",
    "\n",
    "i = torch.tensor(1)\n",
    "print(i, i.dtype)\n",
    "x = torch.tensor(2.0)\n",
    "print(x, x.dtype)\n",
    "b = torch.tensor(True)\n",
    "print(b, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1], dtype=torch.int32) torch.int32\ntensor(2., dtype=torch.float64) torch.float64\n"
    }
   ],
   "source": [
    "# 指定数据类型\n",
    "i = torch.tensor([1], dtype=torch.int32)\n",
    "print(i, i.dtype)\n",
    "x = torch.tensor(2.0, dtype=torch.double)\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "i_v = i.detach()\n",
    "i_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([2], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "i_v  # share the same memory with the origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([3], dtype=torch.int32) torch.int32\ntensor([2.]) torch.float32\ntensor([ True,  True, False]) torch.bool\n"
    }
   ],
   "source": [
    "# 使用特定类型构造函数\n",
    "i = torch.IntTensor([3])  # 不输入list的话, 就是随机出指定个数的tensor\n",
    "print(i, i.dtype)\n",
    "x = torch.FloatTensor([2])\n",
    "print(x, x.dtype)\n",
    "b = torch.BoolTensor([1, 2, 0])\n",
    "print(b, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.])\ntensor([1.])\ntensor([True])\n"
    }
   ],
   "source": [
    "# 不同类型转换\n",
    "i = torch.tensor([1])\n",
    "x = i.float()\n",
    "i = x.type(torch.float32)\n",
    "print(x)\n",
    "print(i)\n",
    "z = i.type_as(b)\n",
    "print(z)"
   ]
  },
  {
   "source": [
    "## 二、张量的维度\n",
    "不同类型的数据可以用不同维度的张量来表示\n",
    "\n",
    "标量为0维张量, 向量为1维张量, 矩阵为2维张量。\n",
    "\n",
    "彩色图像有rgb三个通道, 可以表示为3维张量。\n",
    "\n",
    "视频还有时间维度, 可以表示为4维张量。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(2)\n0\n"
    }
   ],
   "source": [
    "scalar = torch.tensor(2)\n",
    "print(scalar)\n",
    "print(scalar.dim())  # 标量, 0维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3., 4.])\n1\n"
    }
   ],
   "source": [
    "vector = torch.tensor([1.0, 2.0, 3.0, 4.0])  # 向量, 1维张量\n",
    "print(vector)\n",
    "print(vector.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 2.],\n        [2., 4.]])\n2\n"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1.0, 2.0], [2.0, 4.0]])\n",
    "print(matrix)\n",
    "print(matrix.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1., 2.]],\n\n        [[3., 4.]],\n\n        [[5., 5.]]])\n3\n"
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[[1., 2.]], [[3., 4.]], [[5., 5.]]])\n",
    "print(tensor3)\n",
    "print(tensor3.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[[1., 1.],\n          [2., 2.]],\n\n         [[3., 3.],\n          [4., 4.]]],\n\n\n        [[[5., 5.],\n          [6., 6.]],\n\n         [[7., 7.],\n          [8., 8.]]]])\n4\n"
    }
   ],
   "source": [
    "tensor4 = torch.tensor([[[[1.0,1.0],[2.0,2.0]],[[3.0,3.0],[4.0,4.0]]],\n",
    "                        [[[5.0,5.0],[6.0,6.0]],[[7.0,7.0],[8.0,8.0]]]])  # 4维张量\n",
    "print(tensor4)\n",
    "print(tensor4.dim())"
   ]
  },
  {
   "source": [
    "## 三、张量的尺寸\n",
    "可以使用shape属性或者size方法查看张量在每一维度的长度\n",
    "\n",
    "可以使用view方法改变张量尺寸\n",
    "\n",
    "如果view方法改变尺寸失败, 可以使用reshape方法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1])\ntorch.Size([1])\n"
    }
   ],
   "source": [
    "scalar = torch.tensor([True])\n",
    "print(scalar.size())\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4])\ntorch.Size([4])\n"
    }
   ],
   "source": [
    "vector = torch.tensor([1.0,2.0,3.0,4.0])\n",
    "print(vector.size())\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\ntorch.Size([12])\ntensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])\ntorch.Size([3, 4])\n"
    }
   ],
   "source": [
    "# 使用view可以改变张量尺寸\n",
    "vector = torch.arange(0, 12)\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "\n",
    "matrix34 = vector.view(3, 4)\n",
    "print(matrix34)\n",
    "print(matrix34.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "v_r = vector.reshape([3, 4])\n",
    "v_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False False False\n"
    }
   ],
   "source": [
    "print(id(vector) == id(matrix34), id(vector) == id(v_r), id(matrix34) == id(v_r))  # 这个变量其实只是指向了记录tensor的形状(size)、步长(stride)、数据类型(type)等信息的内存区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True True True\n"
    }
   ],
   "source": [
    "print(id(vector.storage()) == id(v_r.storage()), id(vector.storage()) == id(matrix34.storage()), id(matrix34.storage()) == id(v_r.storage()))  # 这三个的储存一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0,  1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10, 11]])\ntorch.Size([2, 6])\nTrue\nFalse\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-af98de82a146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 直接使用view会导致方法失败\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmatrix34\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix62\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# 有些操作会让张量储存结构扭曲, 直接使用view会失败, 可以使用reshape方法\n",
    "\n",
    "matrix26 = torch.arange(0, 12).view(2, 6)\n",
    "print(matrix26)\n",
    "print(matrix26.shape)\n",
    "# 转置操作让张量储存结构扭曲\n",
    "matrix62 = matrix26.t()\n",
    "print(id(matrix26.storage()) == id(matrix62.storage()))\n",
    "print(matrix62.is_contiguous())\n",
    "\n",
    "# 直接使用view会导致方法失败\n",
    "matrix34 = matrix62.view(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "matrix34 = matrix62.reshape([3, 4])\n",
    "print(matrix34.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\n"
    }
   ],
   "source": [
    "print(id(matrix34.storage()) == id(matrix62.storage()))\n",
    "print(id(matrix34.storage()) == id(matrix26.storage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0,  6,  1,  7],\n        [ 2,  8,  3,  9],\n        [ 4, 10,  5, 11]])"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "matrix34_c = matrix34.clone()\n",
    "matrix34_c[0, 0] = 100\n",
    "matrix34  # matrix34不会改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix34_v = matrix34.view(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[100,   6,   1,   7],\n        [  2,   8,   3,   9],\n        [  4,  10,   5,  11]])"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "matrix34_v[0, 0] = 100  # view会改变原来的值\n",
    "matrix34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[110,   6,   1,   7],\n        [  2,   8,   3,   9],\n        [  4,  10,   5,  11]])"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "matrix34_r = matrix34.reshape([3, 4])\n",
    "matrix34_r[0, 0] = 110\n",
    "matrix34  # 这时的reshape返回的是view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nTrue\n"
    }
   ],
   "source": [
    "print(id(matrix34_c.storage()) == id(matrix34.storage()))\n",
    "print(id(matrix34_v.storage()) == id(matrix34.storage()))\n",
    "print(id(matrix34_r.storage()) == id(matrix34.storage()))\n",
    "# 三个使用的储存器又是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "139996598936520\n139996598937096\n139996598937864\n139996598937544\n"
    }
   ],
   "source": [
    "print(id(matrix34.storage()))\n",
    "print(id(matrix34_v.storage()))\n",
    "print(id(matrix34_r.storage()))\n",
    "print(id(matrix34_c.storage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "print(matrix34.storage() is matrix34_v.storage())"
   ]
  },
  {
   "source": [
    "## 四、张量和numpy数组\n",
    "可以使用numpy方法从Tensor得到numpy数组, 也可以用torch.from_numpy从numpy数组中得到Tensor\n",
    "\n",
    "这两种方法关联的Tensor和numpy数组是共享数据内存的\n",
    "\n",
    "如果改变其中一个, 另一个的值也会发生改变。\n",
    "\n",
    "如果有需要, 可以使用张量的clone方法拷贝张量, 中断这种关联。\n",
    "\n",
    "此外, 还可以使用item方法从标量张量得到对应的Python数值。\n",
    "\n",
    "使用tolist方法获得对于的Python数值列表。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before add 1:\n[0. 0. 0.]\ntensor([0., 0., 0.], dtype=torch.float64)\n\n after add 1:\n[1. 1. 1.]\ntensor([1., 1., 1.], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# torch.from_numpy函数从numpy数组\n",
    "arr = np.zeros(3)\n",
    "tensor = torch.from_numpy(arr)\n",
    "print(\"before add 1:\")\n",
    "print(arr)\n",
    "print(tensor)\n",
    "\n",
    "print(\"\\n after add 1:\")\n",
    "# np.add(arr, 1, out = arr)\n",
    "arr += 1\n",
    "print(arr)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before add 1:\ntensor([0., 0., 0.])\n[0. 0. 0.]\n\nafter add 1:\ntensor([1., 1., 1.])\n[0. 0. 0.]\n"
    }
   ],
   "source": [
    "# 可以用clone() 方法拷贝张量，中断这种关联\n",
    "\n",
    "tensor = torch.zeros(3)\n",
    "\n",
    "#使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立\n",
    "arr = tensor.clone().numpy() # 也可以使用tensor.data.numpy()\n",
    "print(\"before add 1:\")\n",
    "print(tensor)\n",
    "print(arr)\n",
    "\n",
    "print(\"\\nafter add 1:\")\n",
    "\n",
    "#使用 带下划线的方法表示计算结果会返回给调用 张量\n",
    "tensor += 1\n",
    "print(tensor)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0\n<class 'float'>\ntensor(1.)\n[[0.2645394802093506, 0.6845030188560486], [0.711341917514801, 0.8271015286445618]]\n<class 'list'>\ntensor([[0.2645, 0.6845],\n        [0.7113, 0.8271]])\n"
    }
   ],
   "source": [
    "# item方法和tolist方法可以将张量转换成Python数值和数值列表\n",
    "scalar = torch.tensor(1.0)\n",
    "s = scalar.item()\n",
    "print(s)\n",
    "print(type(s))\n",
    "s += 1\n",
    "print(scalar)\n",
    "tensor = torch.rand(2,2)\n",
    "t = tensor.tolist()\n",
    "print(t)\n",
    "print(type(t))\n",
    "t[0] = 100\n",
    "print(tensor)"
   ]
  }
 ]
}