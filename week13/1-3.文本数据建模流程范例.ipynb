{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600165250398",
   "display_name": "Python 3.7.0 64-bit ('pytorch1.6': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1-3 文本数据建模流程范例"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 一、准备数据\n",
    "这里使用的数据是imdb数据集\n",
    "\n",
    "在torch中预处理文本数据一般使用torchtext或者自定义Dataset\n",
    "\n",
    "下面用torchtext来构建文本分类数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string, re\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000  # 仅考虑最高频的10000个词\n",
    "MAX_LEN = 200  # 每个样本保留200个词的长度\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# 分词方法\n",
    "tokenizer = lambda x: re.sub(\"[%s]\"%string.punctuation, \"\", x).split(\" \")  # 把标点符号去掉并且分割文本\n",
    "\n",
    "# 过滤掉低频词\n",
    "def filterLowFreqWords(arr, vocab):\n",
    "    arr = [[x if x < MAX_WORDS else 0 for x in example] for example in arr]\n",
    "    return arr\n",
    "\n",
    "# 1. 定义各个字段的预处理方法\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer, lower=True, fix_length=MAX_LEN, postprocessing=filterLowFreqWords)\n",
    "\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# 2. 构建表格型dataset\n",
    "# torchtext.data.TabularDataset可读取csv,tsv,json等格式\n",
    "ds_train, ds_test = torchtext.data.TabularDataset.splits(path=\"./data/imdb/\", train=\"train.tsv\", test=\"test.tsv\", format=\"tsv\", fields=[(\"label\", LABEL), (\"text\", TEXT)], skip_header=False)\n",
    "\n",
    "# 3.构建词典\n",
    "TEXT.build_vocab(ds_train)\n",
    "\n",
    "# 4.构建数据管道迭代器\n",
    "train_iter, test_iter = torchtext.data.Iterator.splits((ds_train, ds_test), sort_within_batch=True, sort_key=lambda x: len(x.text), batch_sizes=(BATCH_SIZE, BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name']\n0\n"
    }
   ],
   "source": [
    "# 查看example信息\n",
    "print(ds_train[0].text)\n",
    "print(ds_train[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "108197\n<unk>\n0\n1\n0\n129453\n11457\n"
    }
   ],
   "source": [
    "# 查看词典信息\n",
    "print(len(TEXT.vocab))\n",
    "\n",
    "# itos: index to string\n",
    "print(TEXT.vocab.itos[0])\n",
    "\n",
    "# stoi: string to index\n",
    "print(TEXT.vocab.stoi[\"<unk>\"])  # 未知词\n",
    "print(TEXT.vocab.stoi[\"<pad>\"])  # 填充\n",
    "\n",
    "# freqs: 词频\n",
    "print(TEXT.vocab.freqs[\"<unk>\"])\n",
    "print(TEXT.vocab.freqs[\"a\"])\n",
    "print(TEXT.vocab.freqs[\"good\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([200, 20])\ntensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0])\n"
    }
   ],
   "source": [
    "# 查看数据管道信息\n",
    "# 这里注意有坑: text第0维是句子长度\n",
    "for batch in train_iter:\n",
    "    features = batch.text\n",
    "    labels = batch.label\n",
    "    print(features.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据管道组织成torch.utils.data.DataLoader相似的features, label输出形式\n",
    "class DataLoader:\n",
    "    def __init__(self, data_iter):\n",
    "        super().__init__()\n",
    "        self.data_iter = data_iter\n",
    "        self.length = len(data_iter)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.data_iter:\n",
    "            # 这里换成batch first\n",
    "            yield(torch.transpose(batch.text, 0, 1), torch.unsqueeze(batch.label.float(), dim=1)\n",
    "            )\n",
    "dl_train = DataLoader(train_iter)\n",
    "dl_test = DataLoader(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([20, 200])\ntorch.Size([20, 1])\n"
    }
   ],
   "source": [
    "for features, labels in dl_train:\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "source": [
    "# 二、定义模型\n",
    "在这里采用第三种方式进行构建，并且使用类形式的训练循环"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.seed()\n",
    "\n",
    "class Net(torchkeras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 设置padding_idx参数后在训练过程中将填充的token始终赋值为0\n",
    "        self.embedding = nn.Embedding(num_embeddings=MAX_WORDS, embedding_dim=3, padding_idx=1)\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"conv_1\", nn.Conv1d(in_channels=3, out_channels=16, kernel_size=5))\n",
    "        self.conv.add_module(\"pool_1\", nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module(\"relu_1\", nn.ReLU())\n",
    "        self.conv.add_module(\"conv_2\", nn.Conv1d(in_channels=16, out_channels=128, kernel_size=2))\n",
    "\n",
    "        self.conv.add_module(\"pool_2\", nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module(\"relu_2\", nn.ReLU())\n",
    "\n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module(\"flatten\", nn.Flatten())\n",
    "        self.dense.add_module(\"linear\", nn.Linear(6144, 1))\n",
    "        self.dense.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # print(\"before transpose:\", x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        # print(\"after transpose:\", x.shape)\n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Net(\n  (embedding): Embedding(10000, 3, padding_idx=1)\n  (conv): Sequential(\n    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))\n    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (relu_1): ReLU()\n    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))\n    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (relu_2): ReLU()\n  )\n  (dense): Sequential(\n    (flatten): Flatten()\n    (linear): Linear(in_features=6144, out_features=1, bias=True)\n    (sigmoid): Sigmoid()\n  )\n)\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n         Embedding-1               [-1, 200, 3]          30,000\n            Conv1d-2              [-1, 16, 196]             256\n         MaxPool1d-3               [-1, 16, 98]               0\n              ReLU-4               [-1, 16, 98]               0\n            Conv1d-5              [-1, 128, 97]           4,224\n         MaxPool1d-6              [-1, 128, 48]               0\n              ReLU-7              [-1, 128, 48]               0\n           Flatten-8                 [-1, 6144]               0\n            Linear-9                    [-1, 1]           6,145\n          Sigmoid-10                    [-1, 1]               0\n================================================================\nTotal params: 40,625\nTrainable params: 40,625\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.000763\nForward/backward pass size (MB): 0.287796\nParams size (MB): 0.154972\nEstimated Total Size (MB): 0.443531\n----------------------------------------------------------------\n"
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "model.summary(input_shape=(200,), input_dtype=torch.LongTensor)"
   ]
  },
  {
   "source": [
    "## 三、训练模型\n",
    "这里仿照Keras定义了一个高阶的模型接口Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.where(y_pred>0.5, torch.ones_like(y_pred, dtype=torch.float32), torch.zeros_like(y_pred, dtype = torch.float32))\n",
    "    acc = torch.mean(1-torch.abs(y_true-y_pred))\n",
    "    return acc\n",
    "\n",
    "model.compile(loss_func=nn.BCELoss(), optimizer=torch.optim.Adagrad(model.parameters(), lr=0.02), metrics_dict={\"accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Start Training ...\n\n================================================================================2020-09-15 19:38:26\n{'step': 200, 'loss': 0.755, 'accuracy': 0.509}\n{'step': 400, 'loss': 0.725, 'accuracy': 0.507}\n{'step': 600, 'loss': 0.714, 'accuracy': 0.505}\n{'step': 800, 'loss': 0.709, 'accuracy': 0.507}\n{'step': 1000, 'loss': 0.706, 'accuracy': 0.509}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   1   | 0.706 |  0.509   |  0.691   |     0.53     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:38:43\n{'step': 200, 'loss': 0.684, 'accuracy': 0.563}\n{'step': 400, 'loss': 0.684, 'accuracy': 0.563}\n{'step': 600, 'loss': 0.682, 'accuracy': 0.565}\n{'step': 800, 'loss': 0.682, 'accuracy': 0.566}\n{'step': 1000, 'loss': 0.681, 'accuracy': 0.567}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   2   | 0.681 |  0.567   |  0.685   |    0.556     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:39:01\n{'step': 200, 'loss': 0.659, 'accuracy': 0.629}\n{'step': 400, 'loss': 0.659, 'accuracy': 0.62}\n{'step': 600, 'loss': 0.656, 'accuracy': 0.621}\n{'step': 800, 'loss': 0.654, 'accuracy': 0.621}\n{'step': 1000, 'loss': 0.652, 'accuracy': 0.622}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   3   | 0.652 |  0.622   |  0.664   |     0.6      |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:39:19\n{'step': 200, 'loss': 0.61, 'accuracy': 0.668}\n{'step': 400, 'loss': 0.61, 'accuracy': 0.673}\n{'step': 600, 'loss': 0.608, 'accuracy': 0.674}\n{'step': 800, 'loss': 0.609, 'accuracy': 0.671}\n{'step': 1000, 'loss': 0.608, 'accuracy': 0.672}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   4   | 0.608 |  0.672   |  0.632   |    0.643     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:39:36\n{'step': 200, 'loss': 0.577, 'accuracy': 0.695}\n{'step': 400, 'loss': 0.568, 'accuracy': 0.707}\n{'step': 600, 'loss': 0.566, 'accuracy': 0.705}\n{'step': 800, 'loss': 0.559, 'accuracy': 0.712}\n{'step': 1000, 'loss': 0.557, 'accuracy': 0.715}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   5   | 0.557 |  0.715   |  0.609   |    0.671     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:39:54\n{'step': 200, 'loss': 0.52, 'accuracy': 0.751}\n{'step': 400, 'loss': 0.519, 'accuracy': 0.749}\n{'step': 600, 'loss': 0.518, 'accuracy': 0.749}\n{'step': 800, 'loss': 0.515, 'accuracy': 0.749}\n{'step': 1000, 'loss': 0.512, 'accuracy': 0.75}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   6   | 0.512 |   0.75   |  0.597   |    0.686     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:40:13\n{'step': 200, 'loss': 0.486, 'accuracy': 0.773}\n{'step': 400, 'loss': 0.483, 'accuracy': 0.772}\n{'step': 600, 'loss': 0.479, 'accuracy': 0.773}\n{'step': 800, 'loss': 0.479, 'accuracy': 0.772}\n{'step': 1000, 'loss': 0.471, 'accuracy': 0.777}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   7   | 0.471 |  0.777   |  0.586   |    0.704     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:40:31\n{'step': 200, 'loss': 0.442, 'accuracy': 0.799}\n{'step': 400, 'loss': 0.441, 'accuracy': 0.797}\n{'step': 600, 'loss': 0.438, 'accuracy': 0.798}\n{'step': 800, 'loss': 0.44, 'accuracy': 0.798}\n{'step': 1000, 'loss': 0.438, 'accuracy': 0.798}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   8   | 0.438 |  0.798   |  0.584   |    0.709     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:40:48\n{'step': 200, 'loss': 0.421, 'accuracy': 0.807}\n{'step': 400, 'loss': 0.411, 'accuracy': 0.815}\n{'step': 600, 'loss': 0.408, 'accuracy': 0.818}\n{'step': 800, 'loss': 0.407, 'accuracy': 0.817}\n{'step': 1000, 'loss': 0.408, 'accuracy': 0.817}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   9   | 0.408 |  0.817   |  0.548   |    0.729     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:41:06\n{'step': 200, 'loss': 0.383, 'accuracy': 0.831}\n{'step': 400, 'loss': 0.38, 'accuracy': 0.833}\n{'step': 600, 'loss': 0.381, 'accuracy': 0.833}\n{'step': 800, 'loss': 0.382, 'accuracy': 0.832}\n{'step': 1000, 'loss': 0.382, 'accuracy': 0.832}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   10  | 0.382 |  0.832   |  0.573   |    0.727     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:41:24\n{'step': 200, 'loss': 0.358, 'accuracy': 0.847}\n{'step': 400, 'loss': 0.357, 'accuracy': 0.851}\n{'step': 600, 'loss': 0.358, 'accuracy': 0.846}\n{'step': 800, 'loss': 0.36, 'accuracy': 0.843}\n{'step': 1000, 'loss': 0.361, 'accuracy': 0.843}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   11  | 0.361 |  0.843   |  0.563   |    0.735     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:41:41\n{'step': 200, 'loss': 0.346, 'accuracy': 0.857}\n{'step': 400, 'loss': 0.341, 'accuracy': 0.857}\n{'step': 600, 'loss': 0.341, 'accuracy': 0.855}\n{'step': 800, 'loss': 0.341, 'accuracy': 0.856}\n{'step': 1000, 'loss': 0.342, 'accuracy': 0.854}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   12  | 0.342 |  0.854   |  0.552   |    0.741     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:41:59\n{'step': 200, 'loss': 0.323, 'accuracy': 0.869}\n{'step': 400, 'loss': 0.319, 'accuracy': 0.866}\n{'step': 600, 'loss': 0.321, 'accuracy': 0.865}\n{'step': 800, 'loss': 0.323, 'accuracy': 0.864}\n{'step': 1000, 'loss': 0.324, 'accuracy': 0.863}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   13  | 0.324 |  0.863   |  0.547   |    0.745     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:42:16\n{'step': 200, 'loss': 0.309, 'accuracy': 0.877}\n{'step': 400, 'loss': 0.308, 'accuracy': 0.878}\n{'step': 600, 'loss': 0.308, 'accuracy': 0.874}\n{'step': 800, 'loss': 0.306, 'accuracy': 0.875}\n{'step': 1000, 'loss': 0.307, 'accuracy': 0.875}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   14  | 0.307 |  0.875   |  0.541   |    0.752     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:42:34\n{'step': 200, 'loss': 0.291, 'accuracy': 0.883}\n{'step': 400, 'loss': 0.295, 'accuracy': 0.879}\n{'step': 600, 'loss': 0.293, 'accuracy': 0.881}\n{'step': 800, 'loss': 0.296, 'accuracy': 0.879}\n{'step': 1000, 'loss': 0.293, 'accuracy': 0.88}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   15  | 0.293 |   0.88   |  0.541   |    0.755     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:42:52\n{'step': 200, 'loss': 0.272, 'accuracy': 0.894}\n{'step': 400, 'loss': 0.28, 'accuracy': 0.888}\n{'step': 600, 'loss': 0.279, 'accuracy': 0.889}\n{'step': 800, 'loss': 0.281, 'accuracy': 0.888}\n{'step': 1000, 'loss': 0.279, 'accuracy': 0.889}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   16  | 0.279 |  0.889   |   0.55   |    0.756     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:43:10\n{'step': 200, 'loss': 0.259, 'accuracy': 0.902}\n{'step': 400, 'loss': 0.266, 'accuracy': 0.896}\n{'step': 600, 'loss': 0.265, 'accuracy': 0.897}\n{'step': 800, 'loss': 0.269, 'accuracy': 0.894}\n{'step': 1000, 'loss': 0.268, 'accuracy': 0.894}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   17  | 0.268 |  0.894   |  0.569   |    0.749     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:43:27\n{'step': 200, 'loss': 0.244, 'accuracy': 0.909}\n{'step': 400, 'loss': 0.247, 'accuracy': 0.908}\n{'step': 600, 'loss': 0.251, 'accuracy': 0.904}\n{'step': 800, 'loss': 0.256, 'accuracy': 0.9}\n{'step': 1000, 'loss': 0.256, 'accuracy': 0.901}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   18  | 0.256 |  0.901   |  0.561   |    0.753     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:43:45\n{'step': 200, 'loss': 0.248, 'accuracy': 0.904}\n{'step': 400, 'loss': 0.245, 'accuracy': 0.906}\n{'step': 600, 'loss': 0.24, 'accuracy': 0.909}\n{'step': 800, 'loss': 0.241, 'accuracy': 0.908}\n{'step': 1000, 'loss': 0.244, 'accuracy': 0.907}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   19  | 0.244 |  0.907   |  0.558   |    0.755     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:44:02\n{'step': 200, 'loss': 0.225, 'accuracy': 0.917}\n{'step': 400, 'loss': 0.228, 'accuracy': 0.916}\n{'step': 600, 'loss': 0.231, 'accuracy': 0.913}\n{'step': 800, 'loss': 0.232, 'accuracy': 0.913}\n{'step': 1000, 'loss': 0.234, 'accuracy': 0.91}\n\n +-------+-------+----------+----------+--------------+\n| epoch |  loss | accuracy | val_loss | val_accuracy |\n+-------+-------+----------+----------+--------------+\n|   20  | 0.234 |   0.91   |  0.562   |    0.759     |\n+-------+-------+----------+----------+--------------+\n\n================================================================================2020-09-15 19:44:20\nFinished Training...\n"
    }
   ],
   "source": [
    "# 有时候模型训练过程中不收敛，需要多试几次\n",
    "dfhistory = model.fit(20,dl_train,dl_val=dl_test,log_step_freq= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}