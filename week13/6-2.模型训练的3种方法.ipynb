{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-2 模型训练的3种方法\n",
    "\n",
    "Pytorch通常需要用户自定义编写训练循环, 训练循环的代码风格因人而异。\n",
    "\n",
    "一般有三种形式：\n",
    "1. 脚本形式循环\n",
    "2. 函数形式循环\n",
    "3. 类形式循环\n",
    "\n",
    "下面以minist数据集训练为例, 演示这三种训练模型的风格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torchkeras import summary,Model \n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MINIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MINIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MINIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MINIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MINIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MINIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MINIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MINIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MINIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MINIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MINIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MINIST/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch1.6/lib/python3.7/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"./data/MINIST\", train=True, download=True, transform=transform)\n",
    "ds_valid = torchvision.datasets.MNIST(root=\"./data/MINIST\", train=False, download=True, transform=transform)\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "print(len(ds_train))\n",
    "print(len(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看部分样本\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    img, label = ds_train[i]\n",
    "    img = torch.squeeze(img)\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = {:d}\".format(int(label)))  # 没有用target_transform\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、脚本风格\n",
    "脚本风格的训练循环最为常见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten()\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3))\n",
    "net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "net.add_module(\"conv2\",nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5))\n",
    "net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "net.add_module(\"flatten\",nn.Flatten())\n",
    "net.add_module(\"linear1\",nn.Linear(64,32))\n",
    "net.add_module(\"relu\",nn.ReLU())\n",
    "net.add_module(\"linear2\",nn.Linear(32,10))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             320\n",
      "         MaxPool2d-2           [-1, 32, 15, 15]               0\n",
      "            Conv2d-3           [-1, 64, 11, 11]          51,264\n",
      "         MaxPool2d-4             [-1, 64, 5, 5]               0\n",
      "         Dropout2d-5             [-1, 64, 5, 5]               0\n",
      " AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0\n",
      "           Flatten-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,080\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 53,994\n",
      "Trainable params: 53,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.003906\n",
      "Forward/backward pass size (MB): 0.359695\n",
      "Params size (MB): 0.205971\n",
      "Estimated Total Size (MB): 0.569572\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_shape=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred), dim=1).data\n",
    "    return accuracy_score(y_true,y_pred_cls)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr = 0.01)\n",
    "metric_func = accuracy\n",
    "metric_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training.....\n",
      "[step = 100] loss: 1.746, accuracy: 0.361\n",
      "[step = 200] loss: 1.199, accuracy: 0.576\n",
      "[step = 300] loss: 0.952, accuracy: 0.672\n",
      "[step = 400] loss: 0.867, accuracy: 0.708\n",
      "[step = 500] loss: 0.763, accuracy: 0.746\n",
      "[step = 600] loss: 0.695, accuracy: 0.771\n",
      "[step = 700] loss: 0.647, accuracy: 0.788\n",
      "[step = 800] loss: 0.606, accuracy: 0.802\n",
      "[step = 900] loss: 0.579, accuracy: 0.813\n",
      "[step = 1000] loss: 0.550, accuracy: 0.823\n",
      "[step = 1100] loss: 0.530, accuracy: 0.830\n",
      "[step = 1200] loss: 0.513, accuracy: 0.837\n",
      "[step = 1300] loss: 0.498, accuracy: 0.843\n",
      "[step = 1400] loss: 0.487, accuracy: 0.847\n",
      "[step = 1500] loss: 0.477, accuracy: 0.850\n",
      "[step = 1600] loss: 0.471, accuracy: 0.853\n",
      "[step = 1700] loss: 0.472, accuracy: 0.854\n",
      "[step = 1800] loss: 0.467, accuracy: 0.856\n",
      "[step = 1900] loss: 0.461, accuracy: 0.859\n",
      "[step = 2000] loss: 0.453, accuracy: 0.862\n",
      "[step = 2100] loss: 0.446, accuracy: 0.865\n",
      "[step = 2200] loss: 0.437, accuracy: 0.868\n",
      "[step = 2300] loss: 0.429, accuracy: 0.871\n",
      "[step = 2400] loss: 0.419, accuracy: 0.874\n",
      "[step = 2500] loss: 0.413, accuracy: 0.876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-51c7cd12b152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# 反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.6/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.6/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "log_step_freq = 100\n",
    "\n",
    "dfhistory = pd.DataFrame(columns=[\"epoch\", \"loss\", metric_name, \"val_loss\", \"val_\" + metric_name])\n",
    "print(\"Starting Training.....\")\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # 1. 训练循环\n",
    "    net.train()  # 设置为训练模式\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "    \n",
    "    for step, (features, labels) in enumerate(dl_train, 1):\n",
    "        \n",
    "        # 梯度清0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 正向传播求损失\n",
    "        y_pred = net(features)\n",
    "        loss = loss_func(y_pred, labels)\n",
    "        metric = metric_func(y_pred, labels)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印batch级别的日志\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step%log_step_freq == 0:   \n",
    "            print((\"[step = %d] loss: %.3f, \"+metric_name+\": %.3f\") %\n",
    "                  (step, loss_sum/step, metric_sum/step))\n",
    "    # 2. 验证循环\n",
    "    net.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "\n",
    "    for val_step, (features,labels) in enumerate(dl_valid, 1):\n",
    "        with torch.no_grad():\n",
    "            predictions = net(features)\n",
    "            val_loss = loss_func(predictions,labels)\n",
    "            val_metric = metric_func(predictions,labels)\n",
    "\n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "\n",
    "    # 3，记录日志-------------------------------------------------\n",
    "    info = (epoch, loss_sum/step, metric_sum/step, \n",
    "            val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "    \n",
    "    # 打印epoch级别日志\n",
    "    print((\"\\nEPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "          \"  = %.3f, val_loss = %.3f, \"+\"val_\"+ metric_name+\" = %.3f\") \n",
    "          %info)\n",
    "print('Finished Training...')  # 不等了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、函数风格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.1, inplace=False)\n",
      "    (5): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "    (6): Flatten()\n",
      "    (7): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Dropout2d(p = 0.1),\n",
    "            nn.AdaptiveMaxPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,10)]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             320\n",
      "         MaxPool2d-2           [-1, 32, 15, 15]               0\n",
      "            Conv2d-3           [-1, 64, 11, 11]          51,264\n",
      "         MaxPool2d-4             [-1, 64, 5, 5]               0\n",
      "         Dropout2d-5             [-1, 64, 5, 5]               0\n",
      " AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0\n",
      "           Flatten-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,080\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 53,994\n",
      "Trainable params: 53,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.003906\n",
      "Forward/backward pass size (MB): 0.359695\n",
      "Params size (MB): 0.205971\n",
      "Estimated Total Size (MB): 0.569572\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_shape=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true,y_pred_cls)\n",
    "\n",
    "model = net\n",
    "model.optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
    "model.loss_func = nn.CrossEntropyLoss()\n",
    "model.metric_func = accuracy\n",
    "model.metric_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model,features,labels):\n",
    "    \n",
    "    # 训练模式，dropout层发生作用\n",
    "    model.train()\n",
    "    \n",
    "    # 梯度清零\n",
    "    model.optimizer.zero_grad()\n",
    "    \n",
    "    # 正向传播求损失\n",
    "    predictions = model(features)\n",
    "    loss = model.loss_func(predictions,labels)\n",
    "    metric = model.metric_func(predictions,labels)\n",
    "\n",
    "    # 反向传播求梯度\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    return loss.item(),metric.item()\n",
    "\n",
    "@torch.no_grad()  # 不记录梯度\n",
    "def valid_step(model,features,labels):\n",
    "    \n",
    "    # 预测模式，dropout层不发生作用\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = model(features)\n",
    "    loss = model.loss_func(predictions,labels)\n",
    "    metric = model.metric_func(predictions,labels)\n",
    "    \n",
    "    return loss.item(), metric.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.316053628921509, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试train_step效果\n",
    "features,labels = next(iter(dl_train))\n",
    "train_step(model,features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs,dl_train,dl_valid,log_step_freq):\n",
    "\n",
    "    metric_name = model.metric_name\n",
    "    dfhistory = pd.DataFrame(columns = [\"epoch\",\"loss\",metric_name,\"val_loss\",\"val_\"+metric_name]) \n",
    "    print(\"Start Training...\")\n",
    "\n",
    "    for epoch in range(1,epochs+1):  \n",
    "\n",
    "        # 1，训练循环-------------------------------------------------\n",
    "        loss_sum = 0.0\n",
    "        metric_sum = 0.0\n",
    "        step = 1\n",
    "\n",
    "        for step, (features,labels) in enumerate(dl_train, 1):\n",
    "\n",
    "            loss,metric = train_step(model,features,labels)\n",
    "\n",
    "            # 打印batch级别日志\n",
    "            loss_sum += loss\n",
    "            metric_sum += metric\n",
    "            if step%log_step_freq == 0:   \n",
    "                print((\"[step = %d] loss: %.3f, \"+metric_name+\": %.3f\") %\n",
    "                      (step, loss_sum/step, metric_sum/step))\n",
    "\n",
    "        # 2，验证循环-------------------------------------------------\n",
    "        val_loss_sum = 0.0\n",
    "        val_metric_sum = 0.0\n",
    "        val_step = 1\n",
    "\n",
    "        for val_step, (features,labels) in enumerate(dl_valid, 1):\n",
    "\n",
    "            val_loss,val_metric = valid_step(model,features,labels)\n",
    "\n",
    "            val_loss_sum += val_loss\n",
    "            val_metric_sum += val_metric\n",
    "\n",
    "        # 3，记录日志-------------------------------------------------\n",
    "        info = (epoch, loss_sum/step, metric_sum/step, \n",
    "                val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "        dfhistory.loc[epoch-1] = info\n",
    "\n",
    "        # 打印epoch级别日志\n",
    "        print((\"\\nEPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "              \"  = %.3f, val_loss = %.3f, \"+\"val_\"+ metric_name+\" = %.3f\") \n",
    "              %info)\n",
    "\n",
    "    print('Finished Training...')\n",
    "    return dfhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "[step = 1000] loss: 2.081, accuracy: 0.341\n",
      "[step = 2000] loss: 1.437, accuracy: 0.557\n",
      "[step = 3000] loss: 1.064, accuracy: 0.674\n",
      "\n",
      "EPOCH = 1, loss = 0.898,accuracy  = 0.725, val_loss = 0.158, val_accuracy = 0.956\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "dfhistory = train_model(model,epochs,dl_train,dl_valid,log_step_freq = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、类风格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (net): CnnModel(\n",
      "    (layers): ModuleList(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Dropout2d(p=0.1, inplace=False)\n",
      "      (5): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "      (6): Flatten()\n",
      "      (7): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (8): ReLU()\n",
      "      (9): Linear(in_features=32, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchkeras\n",
    "class CnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Dropout2d(p = 0.1),\n",
    "            nn.AdaptiveMaxPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,10)]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "model = torchkeras.Model(CnnModel())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.numpy(),y_pred_cls.numpy())\n",
    "\n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.Adam(model.parameters(),lr = 0.02),\n",
    "             metrics_dict={\"accuracy\":accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "\n",
      "================================================================================2020-09-27 16:35:10\n",
      "{'step': 1000, 'loss': 2.307, 'accuracy': 0.112}\n",
      "{'step': 2000, 'loss': 2.306, 'accuracy': 0.11}\n",
      "{'step': 3000, 'loss': 2.306, 'accuracy': 0.108}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   1   | 2.306 |  0.108   |  2.303   |    0.101     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2020-09-27 16:36:39\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "dfhistory = model.fit(1, dl_train = dl_train, dl_val=dl_valid, log_step_freq=1000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.6",
   "language": "python",
   "name": "pytorch1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
