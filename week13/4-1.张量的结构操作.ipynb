{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.0 64-bit ('pytorch1.6')",
   "display_name": "Python 3.7.0 64-bit ('pytorch1.6')",
   "metadata": {
    "interpreter": {
     "hash": "32e20fa419d82ae44b3cd2548dcb635120fe40ded07472dbee097e90a87506aa"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 4-1 张量的结构操作"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "张量的操作主要包括：\n",
    "* 张量的结构操作\n",
    "* 张量的数学运算\n",
    "\n",
    "张量结构操作诸如：\n",
    "* 张量创建\n",
    "* 索引切片\n",
    "* 维度变换\n",
    "* 合并分割\n",
    "\n",
    "张量数学运算主要有：\n",
    "* 标量运算\n",
    "* 向量运算\n",
    "* 矩阵运算\n",
    "* 广播机制"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 一、创建张量\n",
    "张量的创建方法中有很多和numpy中创建array的方法很像"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3.])\n"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1, 3, 5, 7, 9])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "b = torch.arange(1, 10, step=2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n         8.8889, 10.0000])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "c = torch.linspace(0.0, 10, 10)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n"
    }
   ],
   "source": [
    "d = torch.zeros([3, 3])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "a = torch.ones((3, 3), dtype=torch.int)\n",
    "b = torch.zeros_like(a, dtype=torch.int)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[5, 5, 5],\n        [5, 5, 5],\n        [5, 5, 5]], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "torch.fill_(b, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# 均匀随机分布\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 10\n",
    "a = minval + (maxval-minval)*torch.rand([5])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.5507,  0.2704,  0.6472],\n        [ 0.2490, -0.3354,  0.4564],\n        [-0.6255,  0.4539, -1.3740]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# 正态分布随机\n",
    "b = torch.normal(torch.zeros(3, 3), std=torch.ones(3, 3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[16.2371, -1.6612,  3.9163],\n        [ 7.4999,  1.5616,  4.0768],\n        [ 5.2128, -8.9407,  6.4601]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# 正态随机分布\n",
    "mean, std = 2, 5\n",
    "c = std*torch.randn([3, 3]) + mean\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([3, 1, 0, 4, 2])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 整数随机排列\n",
    "d = torch.randperm(5)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])\ntensor([[1, 0, 0],\n        [0, 2, 0],\n        [0, 0, 3]])\n"
    }
   ],
   "source": [
    "# 特殊矩阵\n",
    "I = torch.eye(3, 3)  # 单位矩阵\n",
    "print(I)\n",
    "t = torch.diag(torch.tensor([1, 2, 3]))  # 对角矩阵\n",
    "print(t)"
   ]
  },
  {
   "source": [
    "## 二、索引切片\n",
    "张量的索引切片方式和numpy几乎一样。切片时, 支持缺省参数和省略号。\n",
    "\n",
    "可以通过索引和切片对部分元素进行修改。\n",
    "\n",
    "**此外, 对于不规则的切片提取, 可以使用torch.index_select, torch.masked_select, torch.take**\n",
    "\n",
    "**如果想要通过修改张量的某些元素得到新的张量, 可以使用torch.where, torch.masked_fill, torch.index_fill**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[4, 7, 0, 1, 3],\n        [6, 4, 8, 4, 6],\n        [3, 4, 0, 1, 2],\n        [5, 6, 8, 1, 2],\n        [6, 9, 3, 8, 4]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 均匀随机分布\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 10\n",
    "t = torch.floor(minval + (maxval-minval)*torch.rand([5, 5])).int()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[4, 7, 0, 1, 3]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 第0行\n",
    "print(t[[0], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([6, 9, 3, 8, 4], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 倒数第一行\n",
    "print(t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(4, dtype=torch.int32)\ntensor(4, dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 第1行第3列\n",
    "print(t[1, 3])\n",
    "print(t[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[6, 4, 8, 4, 6],\n        [3, 4, 0, 1, 2],\n        [5, 6, 8, 1, 2]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 第1行至第3行\n",
    "print(t[1:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[6, 8],\n        [3, 0],\n        [5, 8]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 第1行至最后一行, 第0行到最后一列每个两列\n",
    "print(t[1:4, :4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 2.],\n        [0., 0.]], requires_grad=True)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# 可以使用索引和切片修改部分元素\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, requires_grad=True)\n",
    "x.detach()[1, :] = torch.tensor([0.0, 0.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 0,  1,  2],\n         [ 3,  4,  5],\n         [ 6,  7,  8]],\n\n        [[ 9, 10, 11],\n         [12, 13, 14],\n         [15, 16, 17]],\n\n        [[18, 19, 20],\n         [21, 22, 23],\n         [24, 25, 26]]])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "a = torch.arange(27).view(3, 3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 1,  4,  7],\n        [10, 13, 16],\n        [19, 22, 25]])\n"
    }
   ],
   "source": [
    "# 省略号可以表示多个冒号\n",
    "print(a[..., 1])"
   ]
  },
  {
   "source": [
    "以上的切片方式相对规则, 对于不规则的切片提取, 可以使用torch.index_select, torch.take, torch.gather, torch.masked_select。\n",
    "\n",
    "考虑班级成绩册的例子, 有4个班级, 每个班级有10个学生, 每个学生7门科目。可以用一个4*10*7的张量来表示。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[55, 95,  3, 18, 37, 30, 93],\n         [17, 26, 15,  3, 20, 92, 72],\n         [74, 52, 24, 58,  3, 13, 24],\n         [81, 79, 27, 48, 81, 99, 69],\n         [56, 83, 20, 59, 11, 15, 24],\n         [72, 70, 20, 65, 77, 43, 51],\n         [61, 81, 98, 11, 31, 69, 91],\n         [93, 94, 59,  6, 54, 18,  3],\n         [94, 88,  0, 59, 41, 41, 27],\n         [69, 20, 68, 75, 85, 68,  0]],\n\n        [[17, 74, 60, 10, 21, 97, 83],\n         [28, 37,  2, 49, 12, 11, 47],\n         [57, 29, 79, 19, 95, 84,  7],\n         [37, 52, 57, 61, 69, 52, 25],\n         [73,  2, 20, 37, 25, 32,  9],\n         [39, 60, 17, 47, 85, 44, 51],\n         [45, 60, 81, 97, 81, 97, 46],\n         [ 5, 26, 84, 49, 25, 11,  3],\n         [ 7, 39, 77, 77,  1, 81, 10],\n         [39, 29, 40, 40,  5,  6, 42]],\n\n        [[50, 27, 68,  4, 46, 93, 29],\n         [95, 68,  4, 81, 44, 27, 89],\n         [ 9, 55, 39, 85, 63, 74, 67],\n         [37, 39,  8, 77, 89, 84, 14],\n         [52, 14, 22, 20, 67, 20, 48],\n         [52, 82, 12, 15, 20, 84, 32],\n         [92, 68, 56, 49, 40, 56, 38],\n         [49, 56, 10, 23, 90,  9, 46],\n         [99, 68, 51,  6, 74, 14, 35],\n         [33, 42, 50, 91, 56, 94, 80]],\n\n        [[18, 72, 14, 28, 64, 66, 87],\n         [33, 50, 75,  1, 86,  8, 50],\n         [41, 23, 56, 91, 35, 20, 31],\n         [ 0, 72, 25, 16, 21, 78, 76],\n         [88, 68, 33, 36, 64, 91, 63],\n         [26, 26,  2, 60, 21,  5, 93],\n         [17, 44, 64, 51, 16,  9, 89],\n         [58, 91, 33, 64, 38, 47, 19],\n         [66, 65, 48, 38, 19, 84, 12],\n         [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "minval = 0\n",
    "maxval = 100\n",
    "scores = torch.floor(minval + (maxval-minval)*torch.rand([4, 10, 7])).int()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 3, 7])\n"
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生, 第5个学生, 第9个学生的全部成绩\n",
    "sel = torch.index_select(scores, dim=1, index=torch.tensor([0, 5, 9]))\n",
    "print(sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[95, 18, 93],\n         [70, 65, 51],\n         [20, 75,  0]],\n\n        [[74, 10, 83],\n         [60, 47, 51],\n         [29, 40, 42]],\n\n        [[27,  4, 29],\n         [82, 15, 32],\n         [42, 91, 80]],\n\n        [[72, 28, 87],\n         [26, 60, 93],\n         [33, 58, 59]]], dtype=torch.int32)\ntorch.Size([4, 3, 3])\n"
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生, 第5个学生, 第9个学生的第1门课程, 第3门课程, 第6门课程\n",
    "q = torch.index_select(torch.index_select(scores, dim=1, index=torch.tensor([0, 5, 9])), dim=2, index=torch.tensor([1, 3, 6]))\n",
    "print(q)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([55, 14, 59], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# 抽取第0个班级第0个学生的第0门课程, 第2个班级的第4个学生的第1门课程, 第3个班级的第9个学生第6门课程\n",
    "# take将输入看做是一个一维数组, 输出和index同形状\n",
    "s = torch.take(scores, torch.tensor([0*0*7+0, 2*10*7+4*7+1, 3*10*7+9*7+6]))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([95, 93, 92, 81, 81, 99, 83, 81, 98, 91, 93, 94, 94, 88, 85, 97, 83, 95,\n        84, 85, 81, 97, 81, 97, 84, 81, 93, 95, 81, 89, 85, 89, 84, 82, 84, 92,\n        90, 99, 91, 94, 80, 87, 86, 91, 88, 91, 93, 89, 91, 84],\n       dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 抽取分数大于80分的分数\n",
    "g = torch.masked_select(scores, scores>=80)\n",
    "g"
   ]
  },
  {
   "source": [
    "以上这些方法仅能提取张量的部分元素, 但不能更改张量的部分元素值得到新的张量。\n",
    "\n",
    "如果要通过修改张量的部分元素值得到新的张量, 可以使用torch.where, torch.index_fill和torch.masked_fill\n",
    "\n",
    "torch.where可以理解为if的张量版本\n",
    "\n",
    "torch.index_fill的选取元素逻辑和torch.index_select相同\n",
    "\n",
    "torch.masked_fill的选取元素逻辑和torch.masked_select相同"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[0, 1, 0, 0, 0, 0, 1],\n         [0, 0, 0, 0, 0, 1, 1],\n         [1, 0, 0, 0, 0, 0, 0],\n         [1, 1, 0, 0, 1, 1, 1],\n         [0, 1, 0, 0, 0, 0, 0],\n         [1, 1, 0, 1, 1, 0, 0],\n         [1, 1, 1, 0, 0, 1, 1],\n         [1, 1, 0, 0, 0, 0, 0],\n         [1, 1, 0, 0, 0, 0, 0],\n         [1, 0, 1, 1, 1, 1, 0]],\n\n        [[0, 1, 0, 0, 0, 1, 1],\n         [0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 1, 0, 1, 1, 0],\n         [0, 0, 0, 1, 1, 0, 0],\n         [1, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 1, 0, 0],\n         [0, 0, 1, 1, 1, 1, 0],\n         [0, 0, 1, 0, 0, 0, 0],\n         [0, 0, 1, 1, 0, 1, 0],\n         [0, 0, 0, 0, 0, 0, 0]],\n\n        [[0, 0, 1, 0, 0, 1, 0],\n         [1, 1, 0, 1, 0, 0, 1],\n         [0, 0, 0, 1, 1, 1, 1],\n         [0, 0, 0, 1, 1, 1, 0],\n         [0, 0, 0, 0, 1, 0, 0],\n         [0, 1, 0, 0, 0, 1, 0],\n         [1, 1, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 1, 0, 0],\n         [1, 1, 0, 0, 1, 0, 0],\n         [0, 0, 0, 1, 0, 1, 1]],\n\n        [[0, 1, 0, 0, 1, 1, 1],\n         [0, 0, 1, 0, 1, 0, 0],\n         [0, 0, 0, 1, 0, 0, 0],\n         [0, 1, 0, 0, 0, 1, 1],\n         [1, 1, 0, 0, 1, 1, 1],\n         [0, 0, 0, 0, 0, 0, 1],\n         [0, 0, 1, 0, 0, 0, 1],\n         [0, 1, 0, 1, 0, 0, 0],\n         [1, 1, 0, 0, 0, 1, 0],\n         [1, 0, 0, 0, 0, 1, 0]]])\n"
    }
   ],
   "source": [
    "# 如果分数大于60, 赋值为1, 否则赋值为0\n",
    "ifpass = torch.where(scores>60, torch.tensor(1), torch.tensor(0))\n",
    "print(ifpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[100, 100, 100, 100, 100, 100, 100],\n         [ 17,  26,  15,   3,  20,  92,  72],\n         [ 74,  52,  24,  58,   3,  13,  24],\n         [ 81,  79,  27,  48,  81,  99,  69],\n         [ 56,  83,  20,  59,  11,  15,  24],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 61,  81,  98,  11,  31,  69,  91],\n         [ 93,  94,  59,   6,  54,  18,   3],\n         [ 94,  88,   0,  59,  41,  41,  27],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 28,  37,   2,  49,  12,  11,  47],\n         [ 57,  29,  79,  19,  95,  84,   7],\n         [ 37,  52,  57,  61,  69,  52,  25],\n         [ 73,   2,  20,  37,  25,  32,   9],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 45,  60,  81,  97,  81,  97,  46],\n         [  5,  26,  84,  49,  25,  11,   3],\n         [  7,  39,  77,  77,   1,  81,  10],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 95,  68,   4,  81,  44,  27,  89],\n         [  9,  55,  39,  85,  63,  74,  67],\n         [ 37,  39,   8,  77,  89,  84,  14],\n         [ 52,  14,  22,  20,  67,  20,  48],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 92,  68,  56,  49,  40,  56,  38],\n         [ 49,  56,  10,  23,  90,   9,  46],\n         [ 99,  68,  51,   6,  74,  14,  35],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 33,  50,  75,   1,  86,   8,  50],\n         [ 41,  23,  56,  91,  35,  20,  31],\n         [  0,  72,  25,  16,  21,  78,  76],\n         [ 88,  68,  33,  36,  64,  91,  63],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 17,  44,  64,  51,  16,   9,  89],\n         [ 58,  91,  33,  64,  38,  47,  19],\n         [ 66,  65,  48,  38,  19,  84,  12],\n         [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# 将每个班级第0个学生, 第5个学生, 第9个学生的全部成绩赋值为满分\n",
    "torch.index_fill(scores, dim=1, index=torch.tensor([0, 5, 9]), value = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[60, 95, 60, 60, 60, 60, 93],\n         [60, 60, 60, 60, 60, 92, 72],\n         [74, 60, 60, 60, 60, 60, 60],\n         [81, 79, 60, 60, 81, 99, 69],\n         [60, 83, 60, 60, 60, 60, 60],\n         [72, 70, 60, 65, 77, 60, 60],\n         [61, 81, 98, 60, 60, 69, 91],\n         [93, 94, 60, 60, 60, 60, 60],\n         [94, 88, 60, 60, 60, 60, 60],\n         [69, 60, 68, 75, 85, 68, 60]],\n\n        [[60, 74, 60, 60, 60, 97, 83],\n         [60, 60, 60, 60, 60, 60, 60],\n         [60, 60, 79, 60, 95, 84, 60],\n         [60, 60, 60, 61, 69, 60, 60],\n         [73, 60, 60, 60, 60, 60, 60],\n         [60, 60, 60, 60, 85, 60, 60],\n         [60, 60, 81, 97, 81, 97, 60],\n         [60, 60, 84, 60, 60, 60, 60],\n         [60, 60, 77, 77, 60, 81, 60],\n         [60, 60, 60, 60, 60, 60, 60]],\n\n        [[60, 60, 68, 60, 60, 93, 60],\n         [95, 68, 60, 81, 60, 60, 89],\n         [60, 60, 60, 85, 63, 74, 67],\n         [60, 60, 60, 77, 89, 84, 60],\n         [60, 60, 60, 60, 67, 60, 60],\n         [60, 82, 60, 60, 60, 84, 60],\n         [92, 68, 60, 60, 60, 60, 60],\n         [60, 60, 60, 60, 90, 60, 60],\n         [99, 68, 60, 60, 74, 60, 60],\n         [60, 60, 60, 91, 60, 94, 80]],\n\n        [[60, 72, 60, 60, 64, 66, 87],\n         [60, 60, 75, 60, 86, 60, 60],\n         [60, 60, 60, 91, 60, 60, 60],\n         [60, 72, 60, 60, 60, 78, 76],\n         [88, 68, 60, 60, 64, 91, 63],\n         [60, 60, 60, 60, 60, 60, 93],\n         [60, 60, 64, 60, 60, 60, 89],\n         [60, 91, 60, 64, 60, 60, 60],\n         [66, 65, 60, 60, 60, 84, 60],\n         [70, 60, 60, 60, 60, 61, 60]]], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "b = torch.masked_fill(scores, scores<60, 60)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[100, 100, 100, 100, 100, 100, 100],\n         [ 17,  26,  15,   3,  20,  92,  72],\n         [ 74,  52,  24,  58,   3,  13,  24],\n         [ 81,  79,  27,  48,  81,  99,  69],\n         [ 56,  83,  20,  59,  11,  15,  24],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 61,  81,  98,  11,  31,  69,  91],\n         [ 93,  94,  59,   6,  54,  18,   3],\n         [ 94,  88,   0,  59,  41,  41,  27],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 28,  37,   2,  49,  12,  11,  47],\n         [ 57,  29,  79,  19,  95,  84,   7],\n         [ 37,  52,  57,  61,  69,  52,  25],\n         [ 73,   2,  20,  37,  25,  32,   9],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 45,  60,  81,  97,  81,  97,  46],\n         [  5,  26,  84,  49,  25,  11,   3],\n         [  7,  39,  77,  77,   1,  81,  10],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 95,  68,   4,  81,  44,  27,  89],\n         [  9,  55,  39,  85,  63,  74,  67],\n         [ 37,  39,   8,  77,  89,  84,  14],\n         [ 52,  14,  22,  20,  67,  20,  48],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 92,  68,  56,  49,  40,  56,  38],\n         [ 49,  56,  10,  23,  90,   9,  46],\n         [ 99,  68,  51,   6,  74,  14,  35],\n         [100, 100, 100, 100, 100, 100, 100]],\n\n        [[100, 100, 100, 100, 100, 100, 100],\n         [ 33,  50,  75,   1,  86,   8,  50],\n         [ 41,  23,  56,  91,  35,  20,  31],\n         [  0,  72,  25,  16,  21,  78,  76],\n         [ 88,  68,  33,  36,  64,  91,  63],\n         [100, 100, 100, 100, 100, 100, 100],\n         [ 17,  44,  64,  51,  16,   9,  89],\n         [ 58,  91,  33,  64,  38,  47,  19],\n         [ 66,  65,  48,  38,  19,  84,  12],\n         [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# in-place操作\n",
    "scores.index_fill_(dim=1, index=torch.tensor([0, 5, 9]), value=100)\n",
    "scores"
   ]
  },
  {
   "source": [
    "### 三、维度变换\n",
    "\n",
    "维度变换相关的主要函数有torch.reshape, torch.squeeze, \n",
    "\n",
    "torch.unsqueeze, torch.transpose\n",
    "\n",
    "torch.reshape可以改变张量形状\n",
    "\n",
    "torch.squeeze可以减少维度\n",
    "\n",
    "torch.unsqueeze可以增加维度\n",
    "\n",
    "torch.transpose可以交换维度"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 3, 3, 2])\ntensor([[[[126, 195],\n          [ 22,  33],\n          [ 78, 161]],\n\n         [[124, 228],\n          [116, 161],\n          [ 88, 102]],\n\n         [[  5,  43],\n          [ 74, 132],\n          [177, 204]]]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 张量的view方法有时会调用失败, 可以使用reshape方法\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 255\n",
    "a = (minval + (maxval-minval)*torch.rand([1, 3, 3, 2])).int()\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 6])\ntensor([[126, 195,  22,  33,  78, 161],\n        [124, 228, 116, 161,  88, 102],\n        [  5,  43,  74, 132, 177, 204]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "# 改成(3, 6)形状的张量\n",
    "b = a.view([3, 6])\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[[126, 195],\n          [ 22,  33],\n          [ 78, 161]],\n\n         [[124, 228],\n          [116, 161],\n          [ 88, 102]],\n\n         [[  5,  43],\n          [ 74, 132],\n          [177, 204]]]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "c = torch.reshape(b, [1, 3, 3, 2])\n",
    "print(c)"
   ]
  },
  {
   "source": [
    "如果张量在某个维度只有一个元素, 利用torch.squeeze可以消除这个维度。\n",
    "\n",
    "torch.unsqueeze的作用和torch.squeeze的作用相反"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 2.]])\ntensor([1., 2.])\ntorch.Size([1, 2])\ntorch.Size([2])\n"
    }
   ],
   "source": [
    "a = torch.tensor([[1.0, 2.0]])\n",
    "s = torch.squeeze(a)\n",
    "print(a)\n",
    "print(s)\n",
    "print(a.shape)\n",
    "print(s.shape)"
   ]
  },
  {
   "source": [
    "torch.transpose可以交换张量的维度, torch.transpose常用于图片储存格式的变换上。\n",
    "\n",
    "如果是二维的矩阵, 通常会调用矩阵的转置方法matrix.t(), 等价于torch.tranpose(matrix, 0, 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 256, 256, 4])\n"
    }
   ],
   "source": [
    "minval = 0\n",
    "maxval = 255\n",
    "# batch, height, width, channel\n",
    "data = torch.floor(minval + (maxval-minval)*torch.rand([100, 256, 256, 4])).int()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 4, 256, 256])\n"
    }
   ],
   "source": [
    "# 交换成Pytorch默认的图片格式 batch, channel, height, width\n",
    "data_t = torch.transpose(torch.transpose(data, 1, 3), 2, 3)\n",
    "print(data_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1, 2, 3],\n        [4, 5, 6]])\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\n"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(matrix)\n",
    "print(matrix.t()) #等价于torch.transpose(matrix,0,1)"
   ]
  },
  {
   "source": [
    "### 四、合并分割\n",
    "可以使用torch.cat方法和torch.stack方法将多个张量合并, 可以用torch.split方法把一个张量分割成多个张量。\n",
    "\n",
    "torch.cat和torch.stack有略微区别, 前者是连接, 不会增加维度, 而后者是堆叠, 会增加维度。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([6, 2])\ntensor([[ 1.,  2.],\n        [ 3.,  4.],\n        [ 5.,  6.],\n        [ 7.,  8.],\n        [ 9., 10.],\n        [11., 12.]])\n"
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2], [3, 4]])\n",
    "b = torch.tensor([[5., 6], [7, 8]])\n",
    "c = torch.tensor([[9., 10], [11, 12]])\n",
    "\n",
    "abc_cat = torch.cat([a, b, c], dim=0)\n",
    "print(abc_cat.shape)\n",
    "print(abc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 2, 2])\ntensor([[[ 1.,  2.],\n         [ 3.,  4.]],\n\n        [[ 5.,  6.],\n         [ 7.,  8.]],\n\n        [[ 9., 10.],\n         [11., 12.]]])\n"
    }
   ],
   "source": [
    "abc_stack = torch.stack([a, b, c], axis=0)\n",
    "print(abc_stack.shape)\n",
    "print(abc_stack)"
   ]
  },
  {
   "source": [
    "torch.split是torch.cat的逆运算, 可以指定分割平均数, 也可以指定每份记录数量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 2.],\n        [3., 4.]])\ntensor([[5., 6.],\n        [7., 8.]])\ntensor([[ 9., 10.],\n        [11., 12.]])\n"
    }
   ],
   "source": [
    "a, b, c = torch.split(abc_cat, split_size_or_sections=2, dim=0)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 1.,  2.],\n        [ 3.,  4.],\n        [ 5.,  6.],\n        [ 7.,  8.],\n        [ 9., 10.],\n        [11., 12.]])\ntensor([[1., 2.],\n        [3., 4.],\n        [5., 6.],\n        [7., 8.]])\ntensor([[ 9., 10.]])\ntensor([[11., 12.]])\n"
    }
   ],
   "source": [
    "print(abc_cat)\n",
    "p,q,r = torch.split(abc_cat,split_size_or_sections =[4,1,1],dim = 0) #每份分别为[4,1,1]\n",
    "print(p)\n",
    "print(q)\n",
    "print(r)"
   ]
  }
 ]
}