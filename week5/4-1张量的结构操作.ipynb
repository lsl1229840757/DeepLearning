{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-1 张量的结构操作\n",
    "张量的操作主要分为：\n",
    "* 张量的结构操作：张量创建、索引切片、维度变换、合并分割\n",
    "* 张量的数学运算: 标量运算、向量运算、矩阵运算、广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3], dtype = tf.float32)\n",
    "tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "b = tf.range(1, 10, delta = 2)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0.0606060624 0.121212125 ... 5.87878799 5.939394 6]\n",
      "tf.Tensor(\n",
      "[0.         0.06060606 0.12121212 0.18181819 0.24242425 0.3030303\n",
      " 0.36363637 0.42424244 0.4848485  0.54545456 0.6060606  0.6666667\n",
      " 0.72727275 0.7878788  0.8484849  0.90909094 0.969697   1.030303\n",
      " 1.0909091  1.1515152  1.2121212  1.2727273  1.3333334  1.3939395\n",
      " 1.4545455  1.5151515  1.5757576  1.6363637  1.6969697  1.7575758\n",
      " 1.8181819  1.878788   1.939394   2.         2.060606   2.1212122\n",
      " 2.1818182  2.2424242  2.3030305  2.3636365  2.4242425  2.4848485\n",
      " 2.5454545  2.6060607  2.6666667  2.7272727  2.787879   2.848485\n",
      " 2.909091   2.969697   3.030303   3.0909092  3.1515152  3.2121212\n",
      " 3.2727275  3.3333335  3.3939395  3.4545455  3.5151515  3.5757577\n",
      " 3.6363637  3.6969697  3.757576   3.818182   3.878788   3.939394\n",
      " 4.         4.060606   4.121212   4.1818185  4.2424245  4.3030305\n",
      " 4.3636365  4.4242425  4.4848485  4.5454545  4.606061   4.666667\n",
      " 4.727273   4.787879   4.848485   4.909091   4.969697   5.030303\n",
      " 5.090909   5.1515155  5.2121215  5.2727275  5.3333335  5.3939395\n",
      " 5.4545455  5.5151515  5.575758   5.636364   5.69697    5.757576\n",
      " 5.818182   5.878788   5.939394   6.        ], shape=(100,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.linspace(0.0, 2*3, 100)\n",
    "tf.print(c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d = tf.zeros([3, 3])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([3, 3])\n",
    "b = tf.zeros_like(a, dtype = tf.float32)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 5]\n",
      " [5 5]\n",
      " [5 5]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.fill([3, 2], 5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fill in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "fill(dims, value, name=None)\n",
      "    Creates a tensor filled with a scalar value.\n",
      "    \n",
      "    This operation creates a tensor of shape `dims` and fills it with `value`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    >>> tf.fill([2, 3], 9)\n",
      "    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "    array([[9, 9, 9],\n",
      "           [9, 9, 9]], dtype=int32)>\n",
      "    \n",
      "    `tf.fill` evaluates at graph runtime and supports dynamic shapes based on\n",
      "    other runtime `tf.Tensors`, unlike `tf.constant(value, shape=dims)`, which\n",
      "    embeds the value as a `Const` node.\n",
      "    \n",
      "    Args:\n",
      "      dims: A 1-D sequence of non-negative numbers. Represents the shape of the\n",
      "        output `tf.Tensor`. Entries should be of type: `int32`, `int64`.\n",
      "      value: A value to fill the returned `tf.Tensor`.\n",
      "      name: Optional string. The name of the output `tf.Tensor`.\n",
      "    \n",
      "    Returns:\n",
      "      A `tf.Tensor` with shape `dims` and the same dtype as `value`.\n",
      "    \n",
      "    Raises:\n",
      "      InvalidArgumentError: `dims` contains negative entries.\n",
      "      NotFoundError: `dims` contains non-integer entries.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Similar to `np.full`. In `numpy`, more parameters are supported. Passing a\n",
      "    number argument as the shape (`np.full(5, value)`) is valid in `numpy` for\n",
      "    specifying a 1-D shaped result, while TensorFlow does not support this syntax.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4.5562916 4.586997  3.4834461 4.6098537 3.542819 ], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 均匀随机分布\n",
    "a = tf.random.uniform([5], minval = -5, maxval = 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0012541   1.4263123   0.03094142]\n",
      " [ 1.0659183   1.018811   -1.4684073 ]\n",
      " [ 0.34250325 -0.44787502  0.7764029 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 正态分布\n",
    "b = tf.random.normal([3, 3], mean = 0.0, stddev = 1.0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.8885505   1.9866174  -0.9893501   1.157576   -1.542481  ]\n",
      " [ 1.1783073  -1.3005294  -1.15169     1.0989115  -0.6353092 ]\n",
      " [-0.28226504 -1.1738544  -0.61954844  0.17495376 -0.2519497 ]\n",
      " [-0.7041106   0.68609506 -1.2576078  -0.03894141  0.04698461]\n",
      " [-0.6698293  -1.1513939   1.0306796   1.1181413  -0.47335675]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 正态分布, 剔除2倍标准差之外的数据\n",
    "c = tf.random.truncated_normal([5, 5], mean = 0, stddev = 1, dtype = tf.float32)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 特殊矩阵\n",
    "I = tf.eye(3, 3)\n",
    "print(I)\n",
    "t = tf.linalg.diag([1, 2, 3])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 索引切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的索引切片方式和numpy几乎是一样的。切片支持缺省参数和省略号。\n",
    "\n",
    "对于tf.Variable，可以通过索引和切片对部分元素进行修改。\n",
    "\n",
    "对于提取张量的连续子区域，也可以使用tf.slice。\n",
    "\n",
    "此外，对于不规则的切片提取，可以使用tf.gather, tf.gather_nd, tf.boolean_mask\n",
    "\n",
    "其中tf.boolean_mask的功能最为强大, 可以实现其余两者的功能。\n",
    "\n",
    "如果要通过修改张量的某些元素得到新的张量，可以使用tf.where和tf.scatter_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-5  4 -5 -5 -4]\n",
      " [-5  0 -5  0  3]\n",
      " [-4 -5 -1 -3 -4]\n",
      " [-1 -1  0 -3 -1]\n",
      " [-4 -5 -3 -2  3]], shape=(5, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.random.uniform([5, 5], minval = -5, maxval = 5, dtype = tf.int32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5  4 -5 -5 -4], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 第一行\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-4 -5 -3 -2  3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 最后一行\n",
    "print(t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 第一行第三列\n",
    "print(t[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-5  4 -5 -5 -4]\n",
      " [-5  0 -5  0  3]\n",
      " [-4 -5 -1 -3 -4]], shape=(3, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 第1至3行\n",
    "print(t[0:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-5 -5 -4]\n",
      " [-5 -5  3]\n",
      " [-4 -1 -4]\n",
      " [-1  0 -1]\n",
      " [-4 -3  3]], shape=(5, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 第1行到最后一行, 第1列到最后一列每隔2列取一次\n",
    "print(t[:, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上的切片方式相对规则, 如果需要对不规则的切片提取就需要用到tf.gather, tf.gather_nd, tf.boolean_mask\n",
    "\n",
    "例子: 有4个班级, 每个班级10个学生, 每个学生7门科目, 用一个三维张量去表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[11 94 64 27 72  9 87]\n",
      "  [56 48 44 63 78  9 86]\n",
      "  [85 13 23 20 21 28 53]\n",
      "  [77 50 93 47 46 96 26]\n",
      "  [10 27 96 76 24 49 75]\n",
      "  [35 75  2 72 81 14 46]\n",
      "  [91  3 68 87 68 83 22]\n",
      "  [11 43 90 28 55 43 52]\n",
      "  [14  3  5 85 17 13 27]\n",
      "  [23 20 19 64 94 62 15]]\n",
      "\n",
      " [[95 63 47 19 12 70 53]\n",
      "  [ 4 76 45 57 49 49 25]\n",
      "  [91 67 97 36 15 62 44]\n",
      "  [58 15 30 59  3 79 11]\n",
      "  [80 22  2 33 73  1 65]\n",
      "  [24 39 17 53 23 76 67]\n",
      "  [29 94  3 14 48 16 99]\n",
      "  [23 25 34 20 30 95 97]\n",
      "  [12 93 81 77 12 57 12]\n",
      "  [68 11 86 61 73 62 75]]\n",
      "\n",
      " [[12 97 42 95 35 54 52]\n",
      "  [79 71 12 61 99 57 60]\n",
      "  [20  1 15 16 44 75 66]\n",
      "  [78 35 35 80 30 18 37]\n",
      "  [57 11  8 72 67 68 45]\n",
      "  [77 46 17 63 98 67 37]\n",
      "  [21 13 95 83 71 15 74]\n",
      "  [21 88 62 95 41  7 37]\n",
      "  [93 71 95 14  2 85 77]\n",
      "  [99  9 57 50 93 34 10]]\n",
      "\n",
      " [[61 53 30 10 29 30 93]\n",
      "  [ 0 25 39 27  6 67 64]\n",
      "  [31 59 40 66 50 83 51]\n",
      "  [ 1  8 57 53 72 66 23]\n",
      "  [42 30  9 11 25 87 24]\n",
      "  [62 83  7 46 12 97 90]\n",
      "  [57 63 93 18 25 70 41]\n",
      "  [58 29 48 49 33 76 12]\n",
      "  [50 93 17 92  5 83 47]\n",
      "  [16 97 18 67 13 60 24]]], shape=(4, 10, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "scores = tf.random.uniform([4, 10, 7], minval = 0, maxval = 100, dtype = tf.int32)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[11 94 64 27 72  9 87]\n",
      "  [35 75  2 72 81 14 46]\n",
      "  [23 20 19 64 94 62 15]]\n",
      "\n",
      " [[95 63 47 19 12 70 53]\n",
      "  [24 39 17 53 23 76 67]\n",
      "  [68 11 86 61 73 62 75]]\n",
      "\n",
      " [[12 97 42 95 35 54 52]\n",
      "  [77 46 17 63 98 67 37]\n",
      "  [99  9 57 50 93 34 10]]\n",
      "\n",
      " [[61 53 30 10 29 30 93]\n",
      "  [62 83  7 46 12 97 90]\n",
      "  [16 97 18 67 13 60 24]]], shape=(4, 3, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生, 第5个学生和第9个学生的全部成绩\n",
    "p = tf.gather(scores, [0, 5, 9], axis = 1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[94 27 87]\n",
      "  [75 72 46]\n",
      "  [20 64 15]]\n",
      "\n",
      " [[63 19 53]\n",
      "  [39 53 67]\n",
      "  [11 61 75]]\n",
      "\n",
      " [[97 95 52]\n",
      "  [46 63 37]\n",
      "  [ 9 50 10]]\n",
      "\n",
      " [[53 10 93]\n",
      "  [83 46 90]\n",
      "  [97 67 24]]], shape=(4, 3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生, 第5个学生, 第9个学生的第1门课程、第3门课程、第6门课程\n",
    "q = tf.gather(tf.gather(scores, [0, 5, 9], axis = 1), [1, 3, 6], axis = 2)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([94 11 63], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取第0个班级第0个学生, 第2个班级第4个学生, 第三个班级第6个学生的第1门课的成绩\n",
    "s = tf.gather_nd(scores, indices = [(0, 0, 1), (2, 4, 1), (3, 6, 1)])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[11 94 64 27 72  9 87]\n",
      "  [35 75  2 72 81 14 46]\n",
      "  [23 20 19 64 94 62 15]]\n",
      "\n",
      " [[95 63 47 19 12 70 53]\n",
      "  [24 39 17 53 23 76 67]\n",
      "  [68 11 86 61 73 62 75]]\n",
      "\n",
      " [[12 97 42 95 35 54 52]\n",
      "  [77 46 17 63 98 67 37]\n",
      "  [99  9 57 50 93 34 10]]\n",
      "\n",
      " [[61 53 30 10 29 30 93]\n",
      "  [62 83  7 46 12 97 90]\n",
      "  [16 97 18 67 13 60 24]]], shape=(4, 3, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#抽取第0、5、9个学生的全部成绩\n",
    "p = tf.boolean_mask(scores, [True, False, False, False, False, True, False, False, False, True], axis = 1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tf.where和tf.scatter_nd修改张量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[nan  1. nan]\n",
      " [ 2.  2. nan]\n",
      " [ 3. nan  3.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[-1, 1, -1], [2, 2, -2], [3, -3, 3]], dtype = tf.float32)\n",
    "d = tf.where(c < 0, x = tf.fill(c.shape, np.nan), y = c)  # 如果这里传入x, y。那么当条件为真就取x, 条件为假就取y\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [2 1]], shape=(4, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "indices = tf.where(c < 0)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  1. -1.]\n",
      " [ 2.  2. -2.]\n",
      " [ 3.  0.  3.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将张量的第[0,0]和[2,1]两个位置的元素替换为0得到新的张量\n",
    "d = c - tf.scatter_nd([[0, 0], [2, 1]], [c[0, 0], c[2, 1]], c.shape)  # scatter_nd是0初始化的\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 维度变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度变换的函数主要有：\n",
    "* tf.reshape: 可以迅速改变张量形状而不会真的改变储存顺序, 所以该操作十分迅速并且可逆\n",
    "* tf.squeeze: 减少维度\n",
    "* tf.expand_dims: 可以增加维度\n",
    "* tf.transpose: 可以交换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 2)\n",
      "<tf.Variable 'Variable:0' shape=(1, 3, 3, 2) dtype=int32, numpy=\n",
      "array([[[[148,  43],\n",
      "         [184,  17],\n",
      "         [ 78, 224]],\n",
      "\n",
      "        [[223, 128],\n",
      "         [168, 144],\n",
      "         [168, 147]],\n",
      "\n",
      "        [[133,  36],\n",
      "         [178,   4],\n",
      "         [ 86, 244]]]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.random.uniform(shape = [1,3,3,2], minval = 0, maxval = 255, dtype = tf.int32))\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]], shape=(3, 6), dtype=int32)\n",
      "<tf.Variable 'Variable:0' shape=(1, 3, 3, 2) dtype=int32, numpy=\n",
      "array([[[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]]], dtype=int32)>\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]], shape=(3, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[216  96]\n",
      "   [188 215]\n",
      "   [212 194]]\n",
      "\n",
      "  [[ 72 124]\n",
      "   [ 68 224]\n",
      "   [212 180]]\n",
      "\n",
      "  [[ 18 231]\n",
      "   [  4  47]\n",
      "   [123 231]]]], shape=(1, 3, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.reshape(a, [3, 6])  # 值拷贝\n",
    "print(b)\n",
    "a.assign_sub(a)\n",
    "print(a)\n",
    "print(b)\n",
    "a = tf.random.uniform(shape = [1,3,3,2], minval = 0, maxval = 255, dtype = tf.int32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[216  96]\n",
      "  [188 215]\n",
      "  [212 194]]\n",
      "\n",
      " [[ 72 124]\n",
      "  [ 68 224]\n",
      "  [212 180]]\n",
      "\n",
      " [[ 18 231]\n",
      "  [  4  47]\n",
      "  [123 231]]], shape=(3, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "s = tf.squeeze(a)  # 消除1的维度\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[216  96]\n",
      "   [188 215]\n",
      "   [212 194]]\n",
      "\n",
      "  [[ 72 124]\n",
      "   [ 68 224]\n",
      "   [212 180]]\n",
      "\n",
      "  [[ 18 231]\n",
      "   [  4  47]\n",
      "   [123 231]]]], shape=(1, 3, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "d = tf.expand_dims(s, axis = 0)  # 在第一个轴上添加一个维度, \n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 5, 4)\n",
      "(10, 4, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "### Batch, Height, Width, Channel\n",
    "a = tf.random.uniform(shape = [10, 6, 5, 4], minval = 0, maxval = 255, dtype = tf.int32)\n",
    "print(a.shape)\n",
    "\n",
    "# 把Channel end转为Channel first\n",
    "s = tf.transpose(a, perm = [0, 3, 2, 1])\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 合并分割\n",
    "可以使用tf.concat和tf.stack对多个张量进行合并, 可以用tf.split把一个张量分割成多个张量\n",
    "\n",
    "tf.concat和tf.stack有略微的区别, 前者是连接不会增加维度, 后者是堆叠会增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]\n",
      " [ 7.  8.]\n",
      " [ 9. 10.]\n",
      " [11. 12.]], shape=(6, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1.0, 2], [3, 4]])\n",
    "b = tf.constant([[5.0, 6], [7, 8]])\n",
    "c = tf.constant([[9.0, 10], [11, 12]])\n",
    "d = tf.concat([a, b, c], axis = 0)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.  2.]\n",
      "  [ 3.  4.]]\n",
      "\n",
      " [[ 5.  6.]\n",
      "  [ 7.  8.]]\n",
      "\n",
      " [[ 9. 10.]\n",
      "  [11. 12.]]], shape=(3, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.stack([a, b, c], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.  2.]\n",
      "  [ 5.  6.]\n",
      "  [ 9. 10.]]\n",
      "\n",
      " [[ 3.  4.]\n",
      "  [ 7.  8.]\n",
      "  [11. 12.]]], shape=(2, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.stack([a, b, c], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[5., 6.],\n",
      "       [7., 8.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[ 9., 10.],\n",
      "       [11., 12.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# tf.split是tf.concat的逆运算\n",
    "print(tf.split(d, 3, axis = 0))  # 分割成list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 2.]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[3., 4.],\n",
      "       [5., 6.]], dtype=float32)>, <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[ 7.,  8.],\n",
      "       [ 9., 10.],\n",
      "       [11., 12.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(d, [1, 2, 3], axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
