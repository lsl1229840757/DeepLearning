{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-2 张量的数学运算\n",
    "张量的数学运算一般有:\n",
    "* 标量运算\n",
    "* 向量运算\n",
    "* 矩阵运算\n",
    "* 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一 变量运算\n",
    "张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。\n",
    "\n",
    "加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。\n",
    "\n",
    "标量运算符的特点是对张量实施逐元素运算。\n",
    "\n",
    "有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。\n",
    "\n",
    "许多标量运算符都在 **tf.math**模块下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1.0, 2], [-3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\n",
       "array([[False,  True],\n",
       "       [False, False]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a >= 2) & (a <= 3)  # 重载了&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55fe1319f28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "(a >= 2) and (a <= 3)  # 不能使用and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量运算\n",
    "向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。\n",
    "\n",
    "许多向量运算符都以**reduce**开头。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(45, shape=(), dtype=int32)\n",
      "tf.Tensor(362880, shape=(), dtype=int32)\n",
      "tf.Tensor(285, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.range(1, 10)\n",
    "print(tf.reduce_mean(a))\n",
    "print(tf.reduce_sum(a))\n",
    "print(tf.reduce_prod(a))  # 各个维度的乘积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_prod in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_prod(input_tensor, axis=None, keepdims=False, name=None)\n",
      "    Computes the product of elements across dimensions of a tensor.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `axis` is None, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "        dimensions. Must be in the range `[-rank(input_tensor),\n",
      "        rank(input_tensor))`.\n",
      "      keepdims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.prod\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# bool类型的reduce\n",
    "p = tf.constant([True, False, False])\n",
    "q = tf.constant([False, False, True])\n",
    "\n",
    "print(tf.reduce_all(p))  # 逻辑and\n",
    "print(tf.reduce_any(q))  # 逻辑or\n",
    "tf.print(tf.reduce_all(p))  # tf.print输出数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(45, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.foldr函数：This foldr operator repeatedly applies the callable fn to a sequence of elements from last to first, 类似于reduce\n",
    "s = tf.foldr(lambda a,b:a+b, tf.range(10))  # 使用这个函数实现reduce_sum\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1  3  6 10 15 21 28 36 45], shape=(9,), dtype=int32)\n",
      "tf.Tensor([     1      2      6     24    120    720   5040  40320 362880], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.range(1, 10)\n",
    "print(tf.math.cumsum(a))\n",
    "print(tf.math.cumprod(a))  # 积累乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# arg最大最小值索引\n",
    "print(tf.argmax(a))\n",
    "print(tf.argmin(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8 7 5], shape=(3,), dtype=int32)\n",
      "tf.Tensor([5 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.math.top_k 进行排序\n",
    "a = tf.constant([1, 3, 7, 5, 4, 8])\n",
    "values, indices = tf.math.top_k(a, 3, sorted = True)\n",
    "print(values)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三 矩阵运算\n",
    "矩阵必须是二维的。类似tf.constant([1,2,3])这样的不是矩阵。\n",
    "\n",
    "矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。\n",
    "\n",
    "除了一些常用的运算外，大部分和矩阵有关的运算都在**tf.linalg**子包中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1., 2], [3, 4]])  # 定义矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-2.0000002 ,  1.0000001 ],\n",
       "       [ 1.5000001 , -0.50000006]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.inv(a)  # 求逆矩阵要求a必须为浮点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求矩阵的迹\n",
    "tf.linalg.trace(a)  # 对角线之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.477226>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求矩阵的范数\n",
    "tf.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵行列式\n",
    "tf.linalg.det(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.8541021,  5.854102 ], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求矩阵特征向量\n",
    "tf.linalg.eigvalsh(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四，广播机制\n",
    "\n",
    "\n",
    "TensorFlow的广播规则和numpy是一样的:\n",
    "\n",
    "* 1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。\n",
    "* 2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。\n",
    "* 3、如果两个张量在所有维度上都是相容的，它们就能使用广播。\n",
    "* 4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。\n",
    "* 5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2,3])\n",
    "b = tf.constant([[0,0,0],[1,1,1],[2,2,2]])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "b + a  # 等价于b+tf.broadcast_to(a, b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
