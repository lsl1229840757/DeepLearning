{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import selectivesearch\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "from tensorflow.keras import Sequential, layers, Model, models\n",
    "from tensorflow.keras import regularizers\n",
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 把fining好的模型加载进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./AlexNet_fine_tuning_pascal\"\n",
    "alex_net = tf.keras.models.load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              multiple                  34944     \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    multiple                  384       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              multiple                  614656    \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              multiple                  885120    \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  1327488   \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              multiple                  884992    \n",
      "_________________________________________________________________\n",
      "pool_5 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "pred_dense (Dense)           multiple                  257       \n",
      "=================================================================\n",
      "Total params: 3,748,865\n",
      "Trainable params: 3,748,161\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alex_net.summary()  # 这个模型不会保存trainable的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):  # pop掉最后一层\n",
    "    alex_net.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              multiple                  34944     \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    multiple                  384       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              multiple                  614656    \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              multiple                  885120    \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  1327488   \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              multiple                  884992    \n",
      "_________________________________________________________________\n",
      "pool_5 (MaxPooling2D)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 3,748,608\n",
      "Trainable params: 3,747,904\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "原论文中最后一层flatten之后输出的feature特征应该是6 × 6 × 256 = 9216维，而我这里为了加快训练速度使用的图片输入是32*32,\n",
    "所以最后的特征是256维度\n",
    "\"\"\"\n",
    "alex_net.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个描述器\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'bboxes': tf.io.FixedLenSequenceFeature([4], tf.float32, allow_missing=True),  # 用float存的原因是方便后面归一化, 也可以在存之前就归一化\n",
    "    'labels': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "    'labels_text': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    'regions': tf.io.FixedLenSequenceFeature([4], tf.float32, allow_missing=True),\n",
    "    'regions_label':tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "}\n",
    "def parse_image_function(example_proto):\n",
    "    # 把Example转为dict\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = r\".\\data\\PASCAL_VOC_2007_OBJ_car_train_regions.tfrecords\"\n",
    "ds = tf.data.TFRecordDataset(out_dir).map(parse_image_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_raw, regions, regions_label):\n",
    "    \"\"\"\n",
    "        处理之后data应该是regions(32*32), 而输出是0或1\n",
    "    \"\"\"\n",
    "    region_datas = []\n",
    "    img = tf.image.decode_jpeg(image_raw)\n",
    "    for region in regions:\n",
    "        # 按照regions切割原图像\n",
    "        region = tf.cast(region, tf.int64)\n",
    "        xmin, ymin, xmax, ymax = region\n",
    "        region_data = img[ymin: ymax, xmin: xmax, :]\n",
    "        region_data = tf.cast(region_data, tf.float32)\n",
    "        region_data = tf.image.resize(region_data, [32, 32])  # warp\n",
    "        region_data = region_data\n",
    "        region_datas.append(region_data)\n",
    "    return tf.convert_to_tensor(region_datas), tf.convert_to_tensor(regions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_shape(region_datas, regions_label):\n",
    "    return tf.ensure_shape(region_datas, [32, 32, 3]), tf.ensure_shape(regions_label, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds.map(lambda x: (x[\"image_raw\"], x[\"regions\"], x[\"regions_label\"]))  \\\n",
    "                .map(lambda image_raw, regions, regions_label: tf.py_function(func=preprocess,\n",
    "                              inp=[image_raw, regions, regions_label], Tout = [tf.float32, tf.int64])) \\\n",
    "                .unbatch().map(_ensure_shape).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _etract_features(regions_raw, regions_label):\n",
    "    return (alex_net(regions_raw), regions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_svm = ds_train.map(lambda regions_raw, regions_label: tf.py_function(func = _etract_features,\n",
    "                                                                              inp = [regions_raw, regions_label],\n",
    "                                                                             Tout = [tf.float32, tf.int64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于svm需要把所有数据全部读入内存中, 所以这里需要一个转换\n",
    "X = []\n",
    "y = []\n",
    "for region_raw, label in ds_train_svm.unbatch():\n",
    "    X.append(region_raw.numpy())\n",
    "    y.append(label.numpy())\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17822, 256)\n",
      "(17822,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于负样本过多, 这里采用正:负 = 1:3的方式进行降采样, Hints: 如果采用SVC的平衡模式则可以不用这样\n",
    "# X_positive = X[np.where(y == 1)]\n",
    "# y_positive = y[np.where(y == 1)]\n",
    "# num_positive = len(y_positive)\n",
    "# sample_idx = np.random.choice(np.where(y != 1)[0], 3*num_positive, replace=False)\n",
    "# X_negative = X[sample_idx]\n",
    "# y_negative = y[sample_idx]\n",
    "\n",
    "# X_train = np.concatenate([X_positive, X_negative], axis = 0)\n",
    "# y_train = np.concatenate([y_positive, y_negative])\n",
    "# np.random.shuffle(X_train)\n",
    "# np.random.shuffle(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(class_weight = \"balanced\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7810571204129727"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "ground truth: [0 0 0 0 0 0 0 0 1 1]\n",
      "pred:  [0 1 0 0 0 0 0 0 1 1]\n",
      "===========================\n",
      "ground truth: [0 0 0 1 1 0 0 0 0 0]\n",
      "pred:  [0 0 0 1 0 0 0 0 1 0]\n",
      "===========================\n",
      "ground truth: [1 0 0 0 0 1 1 1 0 0]\n",
      "pred:  [1 0 1 0 0 1 1 1 0 0]\n",
      "===========================\n",
      "ground truth: [1 0 0 0 0 0 1 1 0 0]\n",
      "pred:  [1 0 1 0 0 0 1 1 0 0]\n",
      "===========================\n",
      "ground truth: [0 0 0 0 0 0 0 0 0 0]\n",
      "pred:  [0 0 1 0 0 0 0 0 0 0]\n",
      "===========================\n",
      "ground truth: [1 0 0 0 0 0 0 0 0 0]\n",
      "pred:  [1 0 0 0 0 1 1 0 1 0]\n",
      "===========================\n",
      "ground truth: [0 0 1 0 0 0 1 0 0 0]\n",
      "pred:  [0 0 1 0 0 0 1 0 0 0]\n",
      "===========================\n",
      "ground truth: [0 0 0 0 0 1 0 0 0 0]\n",
      "pred:  [1 0 1 0 0 1 0 0 0 0]\n",
      "===========================\n",
      "ground truth: [0 0 0 0 0 0 0 0 0 0]\n",
      "pred:  [0 0 0 0 0 0 1 0 1 0]\n",
      "===========================\n",
      "ground truth: [0 0 0 0 0 0 0 0 0 0]\n",
      "pred:  [1 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for regions_raw, regions_label in ds_train_svm.take(10):\n",
    "    print(\"===========================\")\n",
    "    print(\"ground truth:\", regions_label.numpy())\n",
    "    print(\"pred: \", clf.predict(regions_raw.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**说明：** R-CNN在这里训练SVM还用到了Hard-negative mining，我这里并没有用这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "import joblib\n",
    "model_dir = \"./svm_pascal.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./svm_pascal.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = joblib.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.20508054,  1.33794755, -2.16558059, -2.48448922, -1.66504911,\n",
       "       -0.96871932, -2.22794364, -1.56203662,  1.27573284,  1.0018129 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.decision_function(X[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01470026, 0.79215221, 0.10288423, 0.07695272, 0.15908538,\n",
       "       0.27513584, 0.09726906, 0.1733546 , 0.78172254, 0.73141487])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "expit(s.decision_function(X[0:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
